# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d5nJsWSxpBctMEvXuDt2u7m1ggqncfct
"""

# Download kaggle data in Google Colab
! pip install -q kaggle
from google.colab import files
files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d 'kuantinglai/taiwanese-food-101'
! mkdir taiwanese-food-101
! unzip taiwanese-food-101.zip -d taiwanese-food-101

import tensorflow
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ReduceLROnPlateau
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.layers import Dropout, LeakyReLU, ReLU
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model
import os
import csv
import numpy as np
from tensorflow.keras.models import load_model
import glob, tqdm
from PIL import Image

root_dir = '/content/taiwanese-food-101/tw_food_101/tw_food_101'
train_dir = root_dir + '/train'
test_dir = root_dir + '/test'

# data preprocess
train_datagen = ImageDataGenerator(
        rotation_range=90,
        horizontal_flip=True,
        vertical_flip=True,
        rescale=1./255,)

valid_datagen = ImageDataGenerator(
        rescale=1./255,)

image_size = (180, 180)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=image_size,
    color_mode = "rgb",
    batch_size= 50,
    class_mode='categorical',
    shuffle = True)
valid_generator = valid_datagen.flow_from_directory(
    train_dir,
    target_size=image_size,
    color_mode = "rgb",
    batch_size= 50,
    class_mode='categorical',
    shuffle = True)

base_model = keras.applications.densenet.DenseNet121(include_top=False, weights='imagenet', input_shape=(*image_size, 3))

# dense model
base_model = keras.applications.densenet.DenseNet121(include_top=False, weights='imagenet', input_shape=(*image_size, 3))
# LR function
LR_function=ReduceLROnPlateau(monitor='val_accuracy',
                              patience=3,
                              verbose=1,
                              factor=0.5,# lr*0.5
                              min_lr=0.000001
                             )
adam = Adam(learning_rate=0.0001)

estop = tensorflow.keras.callbacks.EarlyStopping(monitor='loss', patience=6)

scp = tensorflow.keras.callbacks.ModelCheckpoint(
    'model.h5',
    monitor = "val_accuracy",
    verbose = 0,
    save_best_only = True,
    save_weights_only = False,
    mode = "auto",
    save_freq ="epoch",
)

# extra model
x = base_model.output
x = Flatten()(x)
x = Dense(2048, activation='relu')(x)
x = Dense(1024, activation='relu')(x)
x = Dropout(0.5)(x)
pred = Dense(101, activation='softmax')(x)
model = Model(base_model.input, pred)
# comppile
model.compile(optimizer=adam,
            loss='categorical_crossentropy',
            metrics=['accuracy'])

model.summary()

# train
history = model.fit(
      train_generator,
      epochs=20,
      callbacks=[LR_function, estop, scp],
      validation_data=valid_generator,
      validation_steps=None,
      validation_batch_size=None,
      validation_freq=1,
      workers=10
)

# plot acc
train_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
epochs = range(1, len(train_acc) + 1)

plt.plot(epochs, train_acc, 'b', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# plot loss
train_loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(train_loss) + 1)

plt.plot(epochs, train_loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

model.save('model.h5')